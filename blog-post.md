* MIT Distributed systems lectures
* Web is notorious for not being distributed
	* Either you're a client or a server and while you might be able to load offline, you can't continue progressing / updating without the server.
* Why is it desirable for websites to have distributed functionality?
	* Outages: Outages are one which I think people are especially concerned about while the world works through COVID-19
	* Privacy: WebRTC and WebPush were both built with required encryption that is likely solid because so many people are using / reviewing it.  Following standards is more likely to create a secure system than rolling your own if you are not experienced (which I am not).
	* Ease of use: Many people use websites because they have much of the functionality of desktop applications and yet have no installation process.  Current distributed systems usually require some amount of installation and I think this may hinder their adoption.  In fact, there is a market for gateways that adapt existing distributed systems into internet accessible services like Cloudflare's IPFS and Ethereum gateways, or the block explorers, or Stellar's gateway.
* WebRTC provides connection establishment but leaves signaling undefined.  The application layer is expected to implement signaling but there are some signaling services which do that for the developer.
* WebPush is a specification for signaling:
	* Currently the signaling is not intended to be general signaling - a notification is required to be created for each message - but it is signaling all the same.
	* WebPush does not, however, have a specification for encoding the messages from WebRTC into push messages.  This is our job and with the 4k limit is likely going to require a binary protocol.
		* When I started, I just assumed that it could be done and only started to question when I found that the first offer created by Chrome Canary was 6kb.  Luckily using my protocol but zipping it trims the whole initial message to ~1.5kb which should fit even bridged signaling networks.
		* Provide link to protocol specification.
* Who bears the server burden for a distributed web app?
	* By default it would be the browser vendors.  While this might work for smaller networks I could imagine that larger networks could put strain on those services and certainly commercial apps should bear that cost.  I imagine that those networks or large enough communities would end up hosting their own signaling servers that their apps could use.  If they were willing, the standardization of webpush means that they could even support the signaling of other applications.
	* Some amount of using non-builtin push subscriptions would be required anyway to support browsers which don't have webpush support.  Safari doesn't yet and so the application would have to interact with a signaling server manually.  I believe that Mozilla's push network uses websockets exclusively so it might be possible to create/poll web-push subscriptions using javascript for those browsers.  The same manual polling could be used for commercial / community hosted signaling servers.